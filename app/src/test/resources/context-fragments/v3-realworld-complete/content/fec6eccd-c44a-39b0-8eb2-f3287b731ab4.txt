Target file

- source/blender/bmesh/operators/bmo_dupe.cc (contains function `void bmo_spin_exec(BMesh *bm, BMOperator *op)`). This is the single file the Code Agent will modify.

Problem summary (short)

- Current implementation computes a per-step incremental rotation matrix `phi = angle / steps` once and applies it repeatedly to already-transformed geometry. Floating-point rounding accumulates across steps, producing visible drift for large `steps`.

Planned change (concise, for Code Agent)

1) High-level approach
   - Stop applying the same incremental transform to geometry that has already been transformed.
   - For each step i, compute the absolute transform for that step from the original (step-0) vertex positions, and write the new vertex coordinates directly.
   - Keep existing topology generation (duplicate/extrude calls) and the final `use_merge` splicing logic, but replace the `rotate` + `translate` BMO sub-ops that operate incrementally on `geom.out` with direct coordinate assignment using the absolute transforms.

2) Save original vertex indices and coordinates up-front
   - Unconditionally store each original vertex index into the vertex normal memory as currently used in the file (the code already does `*((int *)&v->no[0]) = i;` when `use_merge`). Do this for all vertices regardless of `use_merge` so duplicates/extrudes propagate the original index.
   - Allocate an array sized `bm->totvert` to hold original object-space coordinates, e.g. via MEM_malloc_arrayN for a `float co_orig[bm->totvert][3]`-style buffer. Fill `co_orig[i] = v->co` for each original vertex index `i`.
   - Free the co_orig buffer at the end (MEM_freeN).

3) Read and prepare transform context
   - Read `space` matrix (4x4) from the op input slot and compute inverse (`invert_m4_m4(space_inv, space)`).
   - Read `cent`, `axis`, `dvec`, `steps`, `angle` from op inputs. Normalize `axis` (use `normalize_v3(axis)`) and convert `cent` / vectors into the `space` coordinate system for the computations that follow (positions use full 4x4, vectors use rotation part only).

4) Stable absolute rotations per step
   - Build a unit quaternion `q_total` that represents the total `angle` about `axis`.
   - For each step i (0..steps-1) compute the absolute rotation for the step as the quaternion power: `q_i = pow_qt_fl_normalized(q_total, (float)(i + 1) / (float)steps)` (this gives the rotation that maps step-0 -> step i+1). Convert `q_i` to a 3x3 rotation (or use quaternion-vector multiplication) to rotate vectors.
   - This avoids per-step matrix accumulation and preserves orthonormality.

5) Accurate screw translation accumulation
   - If `use_dvec` (non-zero `dvec`), transform `dvec` into `space` and treat it as a vector. Maintain `double t_accum[3] = {0.0, 0.0, 0.0}` to accumulate world-space translation precisely.
   - For each step i compute `delta = R_i * dvec_space` (where `R_i` is the absolute rotation for step i) and add to `t_accum`. Convert to float only when applying to vertices.

6) Replace incremental BMO rotate/translate with direct assignments
   - After the duplicate/extrude sub-op produces `geom.out`, if this iteration is NOT the last-step `use_merge` special-case, iterate the elements of `geom.out` and for every `BMVert *v_new`:
     - Read original index: `idx = *((int *)&v_new->no[0])`.
     - Get original object-space position `P0_obj = co_orig[idx]`.
     - Compute `P0_space = mul_m4_v3(space, P0_obj)` (apply space transform to position).
     - Compute rotated position about `cent_space`: `P_rot_space = cent_space + R_i * (P0_space - cent_space)`.
     - Add screw translation (if used): `P_space = P_rot_space + (float) t_accum`.
     - Transform back to object space and write `v_new->co = mul_m4_v3(space_inv, P_space)`.
   - Remove or bypass the existing calls which run `BMO_op_callf(... "rotate ... verts=%S" ...)` and `BMO_op_callf(... "translate ... verts=%S" ...)` for `geom.out` in both duplicate and extrude branches; the topology generation continues to be done by those sub-ops but coordinate updates must be done by the new direct assignment.

7) Preserve `use_merge` final-iteration behavior
   - The code already has a special-case for the last iteration when `use_merge` is true: it merges first/last vertices/edges/faces rather than rotating then merging. Preserve this logic. Do not apply the absolute-coordinate overwrite for that last iteration when the current code skips the `rotate`/`translate` and goes straight to splicing.
   - Because original vertex indices are stored in `v->no` for all vertices, the final merge splice code (which looks up `vtable[*((int *)&v_src->no[0])]`) will still work unchanged.

8) Useful helpers & headers already included in the file
   - The file already includes these headers: `BLI_math_matrix.h`, `BLI_math_rotation.h`, `BLI_math_vector.h` which provide functions that will be helpful:
     - `invert_m4_m4`, `mul_m4_v3`, `mul_m3_v3` (matrix/vector transforms)
     - `normalize_v3`
     - `axis_angle_normalized_to_mat3` (used today), quaternion helpers, and `pow_qt_fl_normalized` (to compute quaternion powers precisely)
   - Use `MEM_malloc_arrayN` / `MEM_freeN` for allocation consistent with the rest of the file.

9) Memory and correctness notes
   - The co_orig buffer must be sized `bm->totvert` (use `bm->totvert` which the file already references). Populate it once before the step loop and free after the spin finishes.
   - When converting between spaces, ensure you treat positions (with translation) and vectors (no translation) appropriately: use full 4x4 for positions and only the 3x3 rotation part for vectors.

10) Tests & validation (for implementer)
   - Validate with large `steps` (200–1000) that the final geometry matches the closed-form absolute positions within a tight floating tolerance.
   - Ensure `use_merge` behavior still produces welded geometry for full revolution cases and that `vtable`/index usage is unchanged.

Where to change in the file

- There are two places inside the `for (a = 0; a < steps; a++)` loop where the code currently:
  - calls `duplicate` branch then does `BMO_op_callf(... "rotate ... verts=%S", &dupop, "geom.out")` and copies `geom.out` to `geom_last.out`, and
  - calls `extrude` branch then does a similar `BMO_op_callf(... "rotate ... verts=%S", &extop, "geom.out")` (except for the `use_merge && (a == steps - 1)` special-case).

Replace the rotate/translate BMO calls with the direct coordinate assignments described above, leaving the duplicate/extrude operations themselves in place. Keep the `use_merge` special-case untouched so the final splicing logic still runs.

If anything about the project layout or the function location differs from this note, ask for the exact file snippet to reference. This note intentionally avoids providing source code edits — the Code Agent will perform the modifications using the above plan.

Actionable implementation notes for Code Agent — bmo_spin_exec (no code edits here)

Summary (what to add / why)

- Problem: current spin implementation applies a single incremental rotation (phi = angle / steps) repeatedly to geometry produced in the previous iteration. This causes floating-point rounding to accumulate across steps and produces visible drift for large step counts.
- Fix: compute each step's transform absolutely from the original (step-0) vertices and write coordinates directly for the newly created geometry instead of rotating/translating already-transformed geometry.

How to annotate the source (developer-visible comment)

- Add a brief comment block immediately above `void bmo_spin_exec(BMesh *bm, BMOperator *op)` that explains:
  - The incremental-rotation rounding issue (drift at high step counts).
  - The new approach: store original vertex indices and original coordinates up-front, compute an absolute rotation for each step (via quaternion power or exact axis-angle), accumulate the screw translation in double precision, and reposition each newly created vertex from its original coordinate. Preserve topology creation and `use_merge` splicing behavior.

Where to make data-prep changes (before the step loop)

1) Write original vertex indices into vertex memory (unconditionally):
   - Iterate all BM vertices once (BM_ITER_MESH / BM_ITER_MESH_INDEX). For each vertex `v` assign an original index `i` to the vertex normal storage exactly as the file already uses for the `use_merge` path: `*((int *)&v->no[0]) = i;`.
   - This must be done for all vertices regardless of `use_merge` so that copies/extrusions retain the mapping to the original index.

2) Capture original object-space coordinates: allocate an array sized `bm->totvert` to store the original coordinates for each index.
   - Suggested allocation style: `float (*co_orig)[3] = MEM_malloc_arrayN(bm->totvert, sizeof(*co_orig), __func__);` (adjust to match codebase allocation helpers).
   - As you iterate vertices to write the indices, also store `copy co_orig[i] = v->co`.
   - Free this array at the end of `bmo_spin_exec` (MEM_freeN).

3) Read and prepare transform context (once):
   - Read operator inputs: `space` (4x4 matrix), `cent` (vec3), `axis` (vec3), `dvec` (vec3), `steps` (int), `angle` (float).
   - Normalize `axis`.
   - Compute inverse of `space`: `invert_m4_m4(space_inv, space)`.
   - Convert `cent` into `space` coordinates (apply full 4x4). Convert `dvec` into `space` as a vector (rotate/scale part only, no translation). For vertex positions, when you read `co_orig` use full 4x4. (Implementation note: use `mul_m4_v3` for positions and `mul_m3_v3` or `mul_m3_v3` with the upper-left 3x3 for vectors.)

Rotation math (stable absolute per-step transforms)

- Build a unit quaternion representing the total rotation (axis, total_angle). Helpers are available in the math headers already included in the file.
- For step index `i` (0..steps-1) compute an absolute rotation that maps the original orientation to step `i + 1`:
  - `q_i = pow_qt_fl_normalized(q_total, (float)(i + 1) / (float)steps)` — or compute axis-angle `angle_i = total_angle * (i + 1) / steps` and convert to a 3x3 for rotating vectors.
  - Convert `q_i` to a 3x3 rotation `R_i` (or use quaternion-vector multiply) to apply to vectors in `space` coordinates. This prevents per-step accumulation error and preserves orthonormality.

Screw translation accumulation (high precision)

- If `dvec` is non-zero (screw translation used):
  - Transform `dvec` into `space` as a vector.
  - Maintain a `double t_accum[3] = {0.0, 0.0, 0.0}` to accumulate world-space translation precisely as you iterate steps.
  - On each step `i`, compute `delta = R_i * dvec_space` (rotate the `dvec` using the absolute rotation for step `i`) and add `delta` to `t_accum`. Convert to float only when applying to vertex coordinates.

Where and how to replace incremental rotate/translate (inside the step loop)

- Keep the existing duplicate/extrude sub-operator calls unchanged (they create the topology and fill `geom.out`).
- After the duplicate/extrude runs, skip the old `BMO_op_callf(... "rotate ... verts=%S" ...)` / `BMO_op_callf(... "translate ... verts=%S" ...)` calls operating on `geom.out`.
- Instead, if this iteration is NOT the final `use_merge` special-case, iterate the elements in `geom.out` and when you find vertices do the following for each `BMVert *v_new`:
  1. Read the stored original index: `int idx = *((int *)&v_new->no[0]);`.
  2. Load original object-space position: `float *P0_obj = co_orig[idx];`.
  3. Transform to space: `P0_space = mul_m4_v3(space, P0_obj);`.
  4. Compute rotated position: `P_rot_space = cent_space + R_i * (P0_space - cent_space);`.
  5. Add screw translation: `P_space = P_rot_space + (float) t_accum` (if `use_dvec`).
  6. Transform back to object space: `P_obj_final = mul_m4_v3(space_inv, P_space);` and assign `v_new->co = P_obj_final`.
- Do this replacement in both duplicate and extrude branches where the current code calls `rotate` and `translate` on `geom.out`.

Preserve use_merge merge/splice behavior

- The code has an existing special-case for `use_merge && (a == steps - 1)` where it splices vertices/edges/faces and skips rotating/translating the final step. Keep this special-case intact.
- Since original indices are written into `v->no` for all vertices at the start, the merge path that uses `vtable[*((int *)&v_src->no[0])]` will still work without further changes.

Memory & clean-up

- Free `co_orig` with MEM_freeN(co_orig) before returning from `bmo_spin_exec`.
- If `vtable` is allocated for `use_merge`, continue to free it as currently done.

Notes & available helpers

- The file already includes math headers that provide useful helpers: `invert_m4_m4`, `mul_m4_v3`, `mul_m3_v3`, quaternion helpers and `pow_qt_fl_normalized`.
- Prefer quaternion power or exact axis-angle per-step computations over repeated incremental matrix multiplies to avoid drift.

Testing guidance for Code Agent

- Validate with large steps (200–1000) both with and without `dvec`. The final geometry should match the closed-form absolute positions to a tight tolerance (no visible drift).
- Confirm `use_merge` results in welded geometry for full-revolution cases and that the last-step splice still gets correct original indices.

Reasoning note (for reviewer)

- This appendNote does not change the code. It provides the precise, minimal changes and exact places to modify so the Code Agent can implement the fix without guessing the intent or data flow. The actual C++ changes must be made in `source/blender/bmesh/operators/bmo_dupe.cc` inside `bmo_spin_exec` and should follow the memory/allocation and helper conventions already present in that file.